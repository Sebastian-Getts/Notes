
<!DOCTYPE html>
<html lang="en">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hola">
    <title>tensorflow02 - Hola</title>
    <meta name="author" content="Sebastian Getts">
    
    
    
        
            <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
        
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Sebastian Getts","sameAs":["https://github.com/sebastian-getts/","mailto"],"image":"avatar.jpg"},"articleBody":"试着搭建一个神经网络，总结搭建八股\n\n\n序基于tensorflow的NN：用张量表示数据，用计算图搭建神经网络，用会话执行计算图，优化线上的权重（参数），得到模型。\n\n张量（tensor）：多维数组（列表）\n\n阶：张量的维数\n\n\n\n维数\n阶\n名字\n列子\n\n\n\n0-D\n0\n标量 scalar\ns=1 2 3\n\n\n1-D\n1\n向量 vector\nv=[1,2,3] 数组\n\n\n2-D\n2\n矩阵 matrix\nm=[[1,2,3],[4,5,6],[7,8,9]] 二维数组\n\n\nn-D\nn\n张量 tensor\nt=[[[…]]] n个 方括号有n个就是n阶张量\n\n\n张量可以表示0阶到n阶数组\n\n数据类型：tf.float32 t.int32 …\n\n\ne.g.\n1234567import tensorflow as tfa = tf.constant([1.0,2.0])b = tf.constant([3.0,4.0])result = a + bprint result\n\n12Tensor(&quot;add:0&quot;, shape=(2,),dtype=float32)节点名：第0个输出 维度=一维数组长度2  数据类型 \n\n\n\n计算图搭建神经网络的计算过程，只搭建，不运算。如序中所示。\n123456789import tensorflow as tfx=tf.constant([[1.0,2.0]])w=tf.constant([[3.0],[4.0]])y=tf.matmul(x,w)print y输出：Tensor(&quot;matmul:0&quot;,shape(1,1),dtype=float32)\n\n如果，不清楚python矩阵，试试这个numpy模块的输出：\n12345&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; a = np.arange(15).reshape(3,5)&gt;&gt;&gt; a&gt;&gt;&gt; a.shape\n\n\n\n\n\n会话执行计算图中的节点运算\n\nwith.tf.Session() as sess: print sess.run(y)\n\n1234567891011121314import tensorflow as tfx=tf.constant([[1.0,2.0]])w=tf.constant([[3.0],[4.0]])y=tf.matmul(x,w)print ywith tf.Session() as sess:print sess.run(y)Tensor(&quot;matmul:0&quot;,shape(1,1),dtype=float32)[[11.]]\n\n\n\n参数即权重W，用变量表示，随机给初值。\n\nw = tf.Variable(tf.random_normal([2,3], stddev=2, mean=0, seed=1))\n​                                正态分布    产生2x3矩阵    标准差为2 均值为0  随机种子\n\n\ntf.truncated_normal()        tf.random_uniform()\n去掉过大偏离点的正态分布      平均分布\n\ntf.zeros 全0数组  tf.zeros([3,2],int32) 生产[[0,0],[0,0],[0,0]]\ntf.ones 全1数组  tf.ones([3,2],int32) 生成[[1,1],[1,1],[1,1]]\ntf.fill 全定值数组  tf.fill([3,2],6) 生成[[6,6],[6,6],[6,6]]\ntf.constant 直接给值  tf.constant([3,2,1]) 生成[3,2,1]\n实现过程\n准备数据集，提取特征，作为输入喂给神经网络（Neural Network, NN)\n搭建NN结构，从输入到输出（先搭建计算图，再用会话执行）NN向前传播算法：计算输出\n大量特征数据喂给NN，迭代优化NN参数 NN反向传播算法：优化参数训练模型\n使用训练好的模型预测和分类\n\n1～3为循环的训练过程，4为使用过程\ne.g.; 生产一批零件，将体积x1和重量x2为特征输入NN，通过NN后输出一个数值。\n发现用线性代数的思想去理解传播过程、权重这些东西会好理解一些\ne.g.1\n12345678910111213141516171819#coding:utf-8#两层简单神经网络（全连接）import tensorflow as tf#定义输入和输出x = tf.constant([[0.7,0.5]])w1 = tf.Variable(tf.random_normal([2,3],stddev=1, seed=1))w2 = tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))#定义前向传播过程a = tf.matmul(x, w1)y = tf.matmul(a, w2)#用会话计算结果width tf.Session() as sess:    init_op = tf.global_variables_initializer()    sess.run(init_op)    print&quot;y in tf3_3.py is:\\n&quot;, sess.run(y)    \n\n\n\n12y is:[[3.0904665]]\n\ne.g.2\n12345678910111213141516171819#coding:utf-8#两层简单神经网络（全连接）import tensorflow as tf#定义输入和输出x = tf.constant([[0.7,0.5]])w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1)) #定义前向传播过程a = tf.matmul(x, w1)y = tf.matmul(a, w2)#用会话计算结果with tf.Session() as sess:    init_op = tf.global_variables_initializer()    sess.run(init_op)    print&quot;y in tf3_3.py is:\\n&quot;, sess.run(y)\n\ne.g.3\n123456789101112131415import tensorflow as tfx = tf.placeholder(tf.float32, shape=(None, 2))w1= tf.Variable(tf.random_normal([2,3], stddev=1, seed=1))w2= tf.Variable(tf.random_normal([3,1], stddev=1, seed=1))a = tf.matmul(x, w1)y = tf.matmul(a, w2)with tf.Session() as sess:    init_op = tf.global_variables_initializer()    sess.run(init_op)    print &quot;the result of tf3_5.py is:\\n&quot;, sess.run(y, feed_dict=&#123;x: [[0.7,0.5],[0.2,0.3],[0.3, 0.4],[0.4,0.5]]&#125;)    print &quot;w1:\\n&quot;, sess.run(w1)    print &quot;w2:\\n&quot;, sess.run(w2)\n\n\n\n反向传播训练模型参数，在所有参数上用梯度下降，使NN模型在训练数据上的损失函数最小。\n\n损失函数（loss）：预测值（y）与已知答案（y_）的差距\n\n均方误差MSE：$$MSE(y_,y)=\\frac{\\sum ^n {i=1} (y-y\\)^2}{n}$$\n$$loss = tf.refuce_mean(tf.square(y_-y))$$\n\n\n\n反向传播训练方法：以减小loss值为优化目标\n\n学习率：决定参数每次更新的幅度。（recommand: 0.001)\n\n\ne.g.:\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#coding:utf-8import tensorflow as tfimport  numpy as np #python的科学计算模块BATCH_SIZE = 8 #一次喂入神经网络多少组数据seed = 23455 #基于seed产生随机数rng = np.random.RandomState(seed)#随机数返回32行2列的矩阵 表示32组 体积和中路 作为输入数据集X = rng.rand(32,2)#从X的32行2列的矩阵中 取出一行 判断如果和小于1 给Y赋值1，否则0.Y = [[int(x0+x1 &lt; 1)] for (x0, x1) in X] #是否为真print &quot;X:\\n&quot;,Xprint &quot;Y:\\n&quot;,Y#定义神经网路的输入、参数和输出，，定义前向传播过程x = tf.placeholder(tf.float32, shape=(None, 2))y_= tf.placeholder(tf.float32, shape=(None, 1))w1= tf.Variable(tf.random_normal([2,3], stddev=1, seed=1))w2= tf.Variable(tf.random_normal([3,1], stddev=1, seed=1))a=tf.matmul(x, w1) #矩阵乘法y=tf.matmul(a, w2)#定义损失函数及反向传播方法loss = tf.reduce_mean(tf.square(y-y_)) #均方误差train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss) #梯度下降#train_step = tf.train.MomentumOptimizer(0.001,0.9).minimize(loss)#train_step = tf.train.AdamOptimizer(0.001).minimize(loss)#生成会话，训练STEPS轮with tf.Session() as sess:    init_op = tf.global_variables_initializer()    sess.run(init_op)    print &quot;w1:\\n&quot;, sess.run(w1)    print &quot;w2:\\n&quot;, sess.run(w2)    print &quot;\\n&quot;    #训练模型    STEPS = 3000 #训练3000轮    for i in range(STEPS):        start = (i*BATCH_SIZE) % 32        end = start + BATCH_SIZE        sess.run(train_step, feed_dict=&#123;x: X[start: end], y_:Y[start:end]&#125;)        if i%500 == 0: #每500轮后打印loss            total_loss = sess.run(loss, feed_dict=&#123;x: X, y_: Y&#125;)            print(&quot;After %d training step(s), loss on all data is %g&quot; % (i, total_loss))    #输出训练后的参数取值    print &quot;\\n&quot;    print &quot;w1:\\n&quot;, sess.run(w1)    print &quot;w2:\\n&quot;, sess.run(w2)\n\n\n\n搭建神经网络的八股：准备、前传、反传、迭代\n\n准备 import\n前向传播：定义输入、参数和输出. e.g.: x, y_, w1, w2, a, y\n反向传播：定义损失函数、反向传播方法. e.g.: loss, tran_step\n生成会话，训练STEPS轮\n\n","dateCreated":"2019-12-08T13:05:17+08:00","dateModified":"2020-08-15T19:21:55+08:00","datePublished":"2019-12-08T13:05:17+08:00","description":"试着搭建一个神经网络，总结搭建八股","headline":"tensorflow02","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"http://github.com/sebastian/about/2019/12/08/tensorflow02/"},"publisher":{"@type":"Organization","name":"Sebastian Getts","sameAs":["https://github.com/sebastian-getts/","mailto"],"image":"avatar.jpg","logo":{"@type":"ImageObject","url":"avatar.jpg"}},"url":"http://github.com/sebastian/about/2019/12/08/tensorflow02/","keywords":"tensorflow"}</script>
    <meta name="description" content="试着搭建一个神经网络，总结搭建八股">
<meta property="og:type" content="blog">
<meta property="og:title" content="tensorflow02">
<meta property="og:url" content="http://github.com/sebastian/about/2019/12/08/tensorflow02/index.html">
<meta property="og:site_name" content="Hola">
<meta property="og:description" content="试着搭建一个神经网络，总结搭建八股">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2019-12-08T05:05:17.000Z">
<meta property="article:modified_time" content="2020-08-15T11:21:55.877Z">
<meta property="article:author" content="Sebastian Getts">
<meta property="article:tag" content="tensorflow">
<meta name="twitter:card" content="summary">
    
    
        
    
    
        <meta property="og:image" content="http://github.com/sebastian/about/assets/images/avatar.jpg"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-spzjrm9no8kcbknku5bsn1dr9dpp94iq1g86qdztxtoqwlgtrnwyi2tucypv.min.css">

    <!--STYLES END-->
    

    
    <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?3e3b025a15329c47fcc47a83f6160356";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>


    
        
    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/%20"
            aria-label=""
        >
            Hola
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Open the link: /#about"
            >
        
        
            <img class="header-picture" src="/assets/images/avatar.jpg" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="Read more about the author"
                >
                    <img class="sidebar-profile-picture" src="/assets/images/avatar.jpg" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">Sebastian Getts</h4>
                
                    <h5 class="sidebar-profile-bio"><p>I write code to enrich and ease life of others. 0 errors, 0 warnings.</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="Home"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="Categories"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="Tags"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="Archives"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link open-algolia-search"
                            href="#search"
                            
                            rel="noopener"
                            title="Search"
                        >
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Search</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="About"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/sebastian-getts/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/mailto"
                            
                            rel="noopener"
                            title="Mail"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Mail</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="4"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            tensorflow02
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2019-12-08T13:05:17+08:00">
	
		    Dec 08, 2019
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Tensorflow/">Tensorflow</a>


    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <p>试着搭建一个神经网络，总结搭建八股</p>
<a id="more"></a>

<h1 id="序"><a href="#序" class="headerlink" title="序"></a>序</h1><p>基于tensorflow的NN：用<code>张量</code>表示数据，用<code>计算图</code>搭建神经网络，用<code>会话</code>执行计算图，优化线上的<code>权重</code>（参数），得到模型。</p>
<ul>
<li><p>张量（tensor）：多维数组（列表）</p>
</li>
<li><p>阶：张量的维数</p>
<table>
<thead>
<tr>
<th>维数</th>
<th>阶</th>
<th>名字</th>
<th>列子</th>
</tr>
</thead>
<tbody><tr>
<td>0-D</td>
<td>0</td>
<td>标量 scalar</td>
<td>s=1 2 3</td>
</tr>
<tr>
<td>1-D</td>
<td>1</td>
<td>向量 vector</td>
<td>v=[1,2,3] 数组</td>
</tr>
<tr>
<td>2-D</td>
<td>2</td>
<td>矩阵 matrix</td>
<td>m=[[1,2,3],[4,5,6],[7,8,9]] 二维数组</td>
</tr>
<tr>
<td>n-D</td>
<td>n</td>
<td>张量 tensor</td>
<td>t=[[[…]]] n个 方括号有n个就是n阶张量</td>
</tr>
</tbody></table>
<p>张量可以表示0阶到n阶数组</p>
</li>
<li><p>数据类型：tf.float32 t.int32 …</p>
</li>
</ul>
<p>e.g.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">a = tf.constant([<span class="number">1.0</span>,<span class="number">2.0</span>])</span><br><span class="line">b = tf.constant([<span class="number">3.0</span>,<span class="number">4.0</span>])</span><br><span class="line"></span><br><span class="line">result = a + b</span><br><span class="line"><span class="keyword">print</span> result</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Tensor(<span class="string">&quot;add:0&quot;</span>, shape=(<span class="number">2</span>,),dtype=float32)</span><br><span class="line">节点名：第<span class="number">0</span>个输出 维度=一维数组长度<span class="number">2</span>  数据类型 </span><br></pre></td></tr></table></figure>



<h2 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h2><p>搭建神经网络的计算过程，<strong>只搭建，不运算</strong>。如序中所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">x=tf.constant([[<span class="number">1.0</span>,<span class="number">2.0</span>]])</span><br><span class="line">w=tf.constant([[<span class="number">3.0</span>],[<span class="number">4.0</span>]])</span><br><span class="line"></span><br><span class="line">y=tf.matmul(x,w)</span><br><span class="line"><span class="keyword">print</span> y</span><br><span class="line"></span><br><span class="line">输出：Tensor(<span class="string">&quot;matmul:0&quot;</span>,shape(<span class="number">1</span>,<span class="number">1</span>),dtype=float32)</span><br></pre></td></tr></table></figure>

<p>如果，不清楚python矩阵，试试这个numpy模块的输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.arange(<span class="number">15</span>).reshape(<span class="number">3</span>,<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.shape</span><br></pre></td></tr></table></figure>





<h2 id="会话"><a href="#会话" class="headerlink" title="会话"></a>会话</h2><p>执行计算图中的节点运算</p>
<blockquote>
<p>with.tf.Session() as sess: print sess.run(y)</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">x=tf.constant([[<span class="number">1.0</span>,<span class="number">2.0</span>]])</span><br><span class="line">w=tf.constant([[<span class="number">3.0</span>],[<span class="number">4.0</span>]])</span><br><span class="line"></span><br><span class="line">y=tf.matmul(x,w)</span><br><span class="line"><span class="keyword">print</span> y</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"><span class="keyword">print</span> sess.run(y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Tensor(<span class="string">&quot;matmul:0&quot;</span>,shape(<span class="number">1</span>,<span class="number">1</span>),dtype=float32)</span><br><span class="line">[[<span class="number">11.</span>]]</span><br></pre></td></tr></table></figure>



<h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><p>即<code>权重W</code>，用变量表示，随机给初值。</p>
<blockquote>
<p>w = tf.Variable(tf.random_normal([2,3], stddev=2, mean=0, seed=1))</p>
<p>​                                正态分布    产生2x3矩阵    标准差为2 均值为0  随机种子</p>
</blockquote>
<blockquote>
<p>tf.truncated_normal()        tf.random_uniform()</p>
<p>去掉过大偏离点的正态分布      平均分布</p>
</blockquote>
<p>tf.zeros 全0数组  tf.zeros([3,2],int32) 生产[[0,0],[0,0],[0,0]]</p>
<p>tf.ones 全1数组  tf.ones([3,2],int32) 生成[[1,1],[1,1],[1,1]]</p>
<p>tf.fill 全定值数组  tf.fill([3,2],6) 生成[[6,6],[6,6],[6,6]]</p>
<p>tf.constant 直接给值  tf.constant([3,2,1]) 生成[3,2,1]</p>
<h2 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h2><ol>
<li>准备数据集，提取特征，作为输入喂给神经网络（Neural Network, NN)</li>
<li>搭建NN结构，从输入到输出（先搭建计算图，再用会话执行）<code>NN向前传播算法：计算输出</code></li>
<li>大量特征数据喂给NN，迭代优化NN参数 <code>NN反向传播算法：优化参数训练模型</code></li>
<li>使用训练好的模型预测和分类</li>
</ol>
<p>1～3为循环的训练过程，4为使用过程</p>
<p>e.g.; 生产一批零件，将体积x1和重量x2为特征输入NN，通过NN后输出一个数值。</p>
<p>发现用线性代数的思想去理解传播过程、权重这些东西会好理解一些</p>
<p>e.g.1</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="comment">#两层简单神经网络（全连接）</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义输入和输出</span></span><br><span class="line">x = tf.constant([[<span class="number">0.7</span>,<span class="number">0.5</span>]])</span><br><span class="line">w1 = tf.Variable(tf.random_normal([<span class="number">2</span>,<span class="number">3</span>],stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line">w2 = tf.Variable(tf.random_normal([<span class="number">3</span>,<span class="number">1</span>],stddev=<span class="number">1</span>,seed=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义前向传播过程</span></span><br><span class="line">a = tf.matmul(x, w1)</span><br><span class="line">y = tf.matmul(a, w2)</span><br><span class="line"></span><br><span class="line"><span class="comment">#用会话计算结果</span></span><br><span class="line">width tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    <span class="keyword">print</span><span class="string">&quot;y in tf3_3.py is:\n&quot;</span>, sess.run(y)</span><br><span class="line">    </span><br></pre></td></tr></table></figure>



<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y is:</span><br><span class="line">[[3.0904665]]</span><br></pre></td></tr></table></figure>

<p>e.g.2</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="comment">#两层简单神经网络（全连接）</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义输入和输出</span></span><br><span class="line">x = tf.constant([[<span class="number">0.7</span>,<span class="number">0.5</span>]])</span><br><span class="line">w1 = tf.Variable(tf.random_normal([<span class="number">2</span>, <span class="number">3</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line">w2 = tf.Variable(tf.random_normal([<span class="number">3</span>, <span class="number">1</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line"> </span><br><span class="line"><span class="comment">#定义前向传播过程</span></span><br><span class="line">a = tf.matmul(x, w1)</span><br><span class="line">y = tf.matmul(a, w2)</span><br><span class="line"></span><br><span class="line"><span class="comment">#用会话计算结果</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    <span class="keyword">print</span><span class="string">&quot;y in tf3_3.py is:\n&quot;</span>, sess.run(y)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>e.g.3</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">x = tf.placeholder(tf.float32, shape=(<span class="literal">None</span>, <span class="number">2</span>))</span><br><span class="line">w1= tf.Variable(tf.random_normal([<span class="number">2</span>,<span class="number">3</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line">w2= tf.Variable(tf.random_normal([<span class="number">3</span>,<span class="number">1</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">a = tf.matmul(x, w1)</span><br><span class="line">y = tf.matmul(a, w2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">&quot;the result of tf3_5.py is:\n&quot;</span>, sess.run(y, feed_dict=&#123;x: [[<span class="number">0.7</span>,<span class="number">0.5</span>],[<span class="number">0.2</span>,<span class="number">0.3</span>],[<span class="number">0.3</span>, <span class="number">0.4</span>],[<span class="number">0.4</span>,<span class="number">0.5</span>]]&#125;)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">&quot;w1:\n&quot;</span>, sess.run(w1)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">&quot;w2:\n&quot;</span>, sess.run(w2)</span><br></pre></td></tr></table></figure>



<h1 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h1><p>训练模型参数，在所有参数上用梯度下降，使NN模型在训练数据上的损失函数最小。</p>
<ul>
<li><p>损失函数（loss）：<code>预测值（y）</code>与<code>已知答案（y_）</code>的差距</p>
</li>
<li><p>均方误差MSE：<br>$$<br>MSE(y_,y)=\frac{\sum ^n <em>{i=1} (y-y\</em>)^2}{n}<br>$$</p>
<p>$$<br>loss = tf.refuce_mean(tf.square(y_-y))<br>$$</p>
</li>
</ul>
<ul>
<li><p>反向传播训练方法：以减小loss值为优化目标</p>
</li>
<li><p>学习率：决定参数每次更新的幅度。（recommand: 0.001)</p>
</li>
</ul>
<p>e.g.:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span>  numpy <span class="keyword">as</span> np <span class="comment">#python的科学计算模块</span></span><br><span class="line">BATCH_SIZE = <span class="number">8</span> <span class="comment">#一次喂入神经网络多少组数据</span></span><br><span class="line">seed = <span class="number">23455</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">#基于seed产生随机数</span></span><br><span class="line">rng = np.random.RandomState(seed)</span><br><span class="line"></span><br><span class="line"><span class="comment">#随机数返回32行2列的矩阵 表示32组 体积和中路 作为输入数据集</span></span><br><span class="line">X = rng.rand(<span class="number">32</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#从X的32行2列的矩阵中 取出一行 判断如果和小于1 给Y赋值1，否则0.</span></span><br><span class="line">Y = [[int(x0+x1 &lt; <span class="number">1</span>)] <span class="keyword">for</span> (x0, x1) <span class="keyword">in</span> X] <span class="comment">#是否为真</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">&quot;X:\n&quot;</span>,X</span><br><span class="line"><span class="keyword">print</span> <span class="string">&quot;Y:\n&quot;</span>,Y</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义神经网路的输入、参数和输出，，定义前向传播过程</span></span><br><span class="line">x = tf.placeholder(tf.float32, shape=(<span class="literal">None</span>, <span class="number">2</span>))</span><br><span class="line">y_= tf.placeholder(tf.float32, shape=(<span class="literal">None</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">w1= tf.Variable(tf.random_normal([<span class="number">2</span>,<span class="number">3</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line">w2= tf.Variable(tf.random_normal([<span class="number">3</span>,<span class="number">1</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">a=tf.matmul(x, w1) <span class="comment">#矩阵乘法</span></span><br><span class="line">y=tf.matmul(a, w2)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义损失函数及反向传播方法</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(y-y_)) <span class="comment">#均方误差</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.001</span>).minimize(loss) <span class="comment">#梯度下降</span></span><br><span class="line"><span class="comment">#train_step = tf.train.MomentumOptimizer(0.001,0.9).minimize(loss)</span></span><br><span class="line"><span class="comment">#train_step = tf.train.AdamOptimizer(0.001).minimize(loss)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#生成会话，训练STEPS轮</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> <span class="string">&quot;w1:\n&quot;</span>, sess.run(w1)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">&quot;w2:\n&quot;</span>, sess.run(w2)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">&quot;\n&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#训练模型</span></span><br><span class="line">    STEPS = <span class="number">3000</span> <span class="comment">#训练3000轮</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</span><br><span class="line">        start = (i*BATCH_SIZE) % <span class="number">32</span></span><br><span class="line">        end = start + BATCH_SIZE</span><br><span class="line">        sess.run(train_step, feed_dict=&#123;x: X[start: end], y_:Y[start:end]&#125;)</span><br><span class="line">        <span class="keyword">if</span> i%<span class="number">500</span> == <span class="number">0</span>: <span class="comment">#每500轮后打印loss</span></span><br><span class="line">            total_loss = sess.run(loss, feed_dict=&#123;x: X, y_: Y&#125;)</span><br><span class="line">            print(<span class="string">&quot;After %d training step(s), loss on all data is %g&quot;</span> % (i, total_loss))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#输出训练后的参数取值</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">&quot;\n&quot;</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">&quot;w1:\n&quot;</span>, sess.run(w1)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">&quot;w2:\n&quot;</span>, sess.run(w2)</span><br></pre></td></tr></table></figure>



<h2 id="搭建神经网络的八股："><a href="#搭建神经网络的八股：" class="headerlink" title="搭建神经网络的八股："></a>搭建神经网络的八股：</h2><p>准备、前传、反传、迭代</p>
<ul>
<li>准备 import</li>
<li>前向传播：定义输入、参数和输出. e.g.: x, y_, w1, w2, a, y</li>
<li>反向传播：定义损失函数、反向传播方法. e.g.: loss, tran_step</li>
<li>生成会话，训练STEPS轮</li>
</ul>

            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">TAGGED IN</span><br/>
                
    <a class="tag tag--primary tag--small t-none-link" href="/tags/tensorflow/" rel="tag">tensorflow</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2019/12/10/leecode/"
                    data-tooltip="leecode"
                    aria-label="PREVIOUS: leecode"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2019/12/07/tensorflow01/"
                    data-tooltip="tensorflow01"
                    aria-label="NEXT: tensorflow01"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=http://github.com/sebastian/about/2019/12/08/tensorflow02/"
                    title="Share on Weibo"
                    aria-label="Share on Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://connect.qq.com/widget/shareqq/index.html?url=http://github.com/sebastian/about/2019/12/08/tensorflow02/&amp;title=tensorflow02"
                    title="Share on QQ"
                    aria-label="Share on QQ"
                >
                    <i class="fab fa-qq" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://widget.renren.com/dialog/share?resourceUrl=http://github.com/sebastian/about/2019/12/08/tensorflow02/"
                    title="Share on Renren"
                    aria-label="Share on Renren"
                >
                    <i class="fab fa-renren" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2020 Sebastian Getts. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2019/12/10/leecode/"
                    data-tooltip="leecode"
                    aria-label="PREVIOUS: leecode"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2019/12/07/tensorflow01/"
                    data-tooltip="tensorflow01"
                    aria-label="NEXT: tensorflow01"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=http://github.com/sebastian/about/2019/12/08/tensorflow02/"
                    title="Share on Weibo"
                    aria-label="Share on Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://connect.qq.com/widget/shareqq/index.html?url=http://github.com/sebastian/about/2019/12/08/tensorflow02/&amp;title=tensorflow02"
                    title="Share on QQ"
                    aria-label="Share on QQ"
                >
                    <i class="fab fa-qq" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://widget.renren.com/dialog/share?resourceUrl=http://github.com/sebastian/about/2019/12/08/tensorflow02/"
                    title="Share on Renren"
                    aria-label="Share on Renren"
                >
                    <i class="fab fa-renren" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="4">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://service.weibo.com/share/share.php?&amp;title=http://github.com/sebastian/about/2019/12/08/tensorflow02/"
                        aria-label="Share on Weibo"
                    >
                        <i class="fab fa-weibo" aria-hidden="true"></i><span>Share on Weibo</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://connect.qq.com/widget/shareqq/index.html?url=http://github.com/sebastian/about/2019/12/08/tensorflow02/&amp;title=tensorflow02"
                        aria-label="Share on QQ"
                    >
                        <i class="fab fa-qq" aria-hidden="true"></i><span>Share on QQ</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://widget.renren.com/dialog/share?resourceUrl=http://github.com/sebastian/about/2019/12/08/tensorflow02/"
                        aria-label="Share on Renren"
                    >
                        <i class="fab fa-renren" aria-hidden="true"></i><span>Share on Renren</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/avatar.jpg" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">Sebastian Getts</h4>
        
            <div id="about-card-bio"><p>I write code to enrich and ease life of others. 0 errors, 0 warnings.</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>Software Developer</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Shenzhen
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover-v1.2.0.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-karbquxnkadaf4yf1hq6g6fyv6nvvrwpv3vf2u1wz8k7osddfqtxf5wbfcfg.min.js"></script>

<!--SCRIPTS END-->


    




    </body>
</html>
